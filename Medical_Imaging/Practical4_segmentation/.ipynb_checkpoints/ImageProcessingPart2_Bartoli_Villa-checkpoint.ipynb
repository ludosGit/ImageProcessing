{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Medical Imaging \n",
    "##  Practical session 5: Image Processing - Part II \n",
    "### Image Segmentation\n",
    "###  7th December 2021\n",
    "***\n",
    "**Jakub Ceranka, Sebastian Amador Sanchez, Jef Vandemeulebroucke\\\n",
    "Department of Electronics and Informatics (ETRO)\\\n",
    "Vrije Universitet Brussel, Pleinlaan 2, B-1050 Brussels, Belgium**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Insert students names and IDs here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "For more information on the following concepts see the lecture recordings, course slides and the related study material.\n",
    "\n",
    "### Purpose\n",
    "The goal of this exercise session is to obtain insight in the image segmentation operations and their evaluation metrics commonly applied in medical image processing.\n",
    "\n",
    "\n",
    "### BraTS dataset\n",
    "You will be working with images obtained from the [*Brain Tumor Segmentation (BRATS) Challenge*](http://www.braintumorsegmentation.org), which contains the scans of multiple glioma cases. \n",
    "Gliomas are a type of brain tumor that originate in the glial cells that surround the neurons. They are characterized by having various heterogeneous histological sub-regions, resulting on them having varying intensity profiles. In consequence, to properly visualize them multimodal MRI scans have to be employed, making multimodal segmentation of brain tumors a major challenge in medical image analysis.\n",
    "\n",
    "<img src=\"./images/brats.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "**(A)** Whole tumor visible in T2-FLAIR **(B)** Tumor core visible in T2 **(C)** Enhancing tumor (blue) and necrotic component (green) visible in T1-Contrast **(D)** Tumor sub-regions.\n",
    "\n",
    "You DO NOT have to download the dataset, you have to employ the images acquired in the previous session. If you were not able to obtain them, these are provided within the files. \n",
    "\n",
    "\n",
    "### Instructions\n",
    "The jupyter notebook should be submitted as the report by teams of two using the assignment functionality of Ufora.\n",
    "\n",
    "Please complete this notebook and upload the following before the deadline **21th December, 2021, at 23:59**:\n",
    "- the notebook in *.ipynb* format\n",
    "- the executed notebook in *.html* format (File --> Download As --> HTML)\n",
    "\n",
    "The report should contain concise answers to the questions (in specified cells), python code and plotted figures.\n",
    "For this practical session, we do not require a separate written report in *.pdf* format.\n",
    "\n",
    "#### Questions: [samadors@etrovub.be](mailto:samadors@etrovub.be)\n",
    "\n",
    "### Required modules\n",
    "Before starting make sure you have installed the following libraries:\n",
    "\n",
    "- ```SimpleITK``` -> Read and write images, image operations\n",
    "- ```numpy``` -> Operation with arrays\n",
    "- ```matplotlib == 3.1.3``` -> Plot images\n",
    "- ```Tkinter == 8.6``` -> GUI backend for matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Image segmentation\n",
    "Image segmentation can be defined as any method that results in the partitioning of an image into meaningful regions. This is done by defining the boundaries of a region of interest, known as foreground, which has similar characteristics, such as shape, color or texture. The remaining image volume is known as the background. \n",
    "\n",
    "<img src=\"./images/segmentations.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "**Left:** Retinal blood vessel segmentation. **Center.** Skin cancer lesion segmentation. **Left.** CT lung segmentation.\n",
    "\n",
    "In medical imaging, segmentation is either a preprocessing step or more importantly, a goal itself. For example, the qualitative 3D representation of an organ requires the accurate delineation or segmentation of that organ from the stack of images. Here, the segmentation is used as preprocessing step prior to visualization. In contrast, segmentation is a goal itself in qualitative or quantitative image analysis for specific diagnostic tasks, e.g. tumor size measurements in brain MRI or fetal head measurements in ultrasound.\n",
    "\n",
    "Multiple methods exist and the optimal choice is highly dependent on the region to be segmented, and the type and quality of the image. Regardless the image modality, and according to the image features, two main apporaches can be distinguished: \n",
    "1. **Region based:** We look for uniform regions in an image\n",
    "2. **Edge based:** We look for the boundaries between regions with different characteristics. \n",
    "\n",
    "## 1.1 Thresholding\n",
    "\n",
    "Image thresholding is the simplest and fastest segmentation method. The process comes down to defining one or more boundaries of intensity in the image histogram. Pixels with intensity within the boundaries will get mapped to 1 (inside), while the others will be considered background (0). The process can be extended to multiple labels using multiple (upper and lower) boundaries.\n",
    "\n",
    "<img src=\"./images/thresholding.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "**(i)** Original image **(ii)** Image histogram **(iii)** Too high threshold **(iv)** Too low threshold **(v)** Ideal threshold\n",
    "\n",
    "Despite its simplicity, thresholding is sometimes the least accurate approach. Factors like image contrast, resolution and objects with varying levels of brightness can hamper the performance of thresholding.\n",
    "\n",
    "<img src=\"./images/histograms.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "**(i)** Gray-level hisotgrams approximated by two normal distributions **(ii)** Combined histograms. See third case, where to set the threshold?\n",
    "\n",
    "### Optimal thresholding\n",
    "Thresholding can be done by manually selecting the boundaries, or automatically, by optimizing the boundary values with respect to a certain criterion. For instance, Otsu thresholding will automatically select boundaries that maximize the class variance of two or more regions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1:\n",
    "\n",
    "One of the first algorithms dedicated to finding an optimal threshold is the one proposed by [Otsu N](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4310076). In its simplest form it segments the image histogram in two classes: background and foreground. In this exercises you will apply the [extended version](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.85.3669&rep=rep1&type=pdf) of it to divide an image into multiple regions, and consequently segment the tumor from the MRI image. Additionally, you will get familiarized with post-processing techniques and segmentation evaluation metrics. \n",
    "\n",
    "1. Use ```sitk.ReadImage()``` to read both the MRI image: 'BraTS2021_01666_flair.mha', and the ground truth segmentation: 'BraTS2021_01666_seg.mha' (read the ground truth as sitk.sitkUInt8) from the folder 'BraTS2021_01666'.\n",
    "\n",
    "2. Create a function that performs the Otsu multi-thresholding.\n",
    "\n",
    "    **To create the function:**\n",
    "    - Employ the filter [```sitk.OtsuMultipleThresholdsImageFilter```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1OtsuMultipleThresholdsImageFilter.html).  ```SetNumberOfHistogramBins ``` to 64 and ```SetNumberOfThresholds ``` to 4.\n",
    "    - ```Execute()``` to get the segmented image\n",
    "    - Retrieve the threshold values  using ```GetThresholds()```.\n",
    "    - Return the segmented image and thresholds.\n",
    "    \n",
    "3. See the results using the provided function ```show_segments()```. Select the segment where the tumor is present. Since it is surrounded by unwanted components, design a function that extracts the tumor from the rest of the elements. To achieve this, search for the component with the highest number of pixels. Keep this image for exercise 1.2, display it using ```show_image```.\n",
    "\n",
    "    **To create the function that selects the desired component:**\n",
    "    - Employ [```sitk.ConnectedComponentImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1ConnectedComponentImageFilter.html) to label all the components of the segmented image. Set ```SetFullyConnected()``` to True. \n",
    "    - Afterwards, use [```sitk.LabelShapeStatisticsImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1LabelShapeStatisticsImageFilter.html) to compute the shape statistics over the resultant labeled image. \n",
    "    - Utilize ```GetNumberOfLabels()``` to obtain the number of components in the image, and use ```GetNumberOfPixels()``` to get the number of pixels per labeled component. Retrieve the element with the max number of pixels. Ignore the background, otherwise you will retrieve this element.\n",
    "    - **hint:** Use ```.index()``` and ```max()``` to obtain the index of the element with the max number of pixels.\n",
    "\n",
    "4. Post-processing. Apply the following post-processing methods to the segmentation of step 4. Display the result using ```show_image```.\n",
    "    - [```sitk.BinaryFillholeImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1BinaryFillholeImageFilter.html), ```SetForegroundValue``` to 1\n",
    "    - [```sitk.BinaryDilateImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1BinaryDilateImageFilter.html), ```SetForegroundValue``` to 1, ```SetKernelRadius ``` equal to 2  and ```SetKernelType``` equal to ```sitk.sitkBall()```.\n",
    "\n",
    "5. Calcualte the DICE and Jaccard coefficient, along with the false positive error and false negative error using [```sitk.LabelOverlapMeasuresImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1LabelOverlapMeasuresImageFilter.html). Additionally, calculate the Hausdorff distance employing [```sitk.HausdorffDistanceImageFilter()```](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1HausdorffDistanceImageFilter.html). \n",
    "\n",
    "    It is recommended to create a function ```evaluate()```, which takes two input arguments - binary ground truth and binary segmentation results - and returns all validation criteria at once. Keep in mind that the input for the evaluation metrics should be a binary image of type ```sitk.sitkUInt8```. If your image type has to be changed, use ```sitk.Cast()``` filter.\n",
    "\n",
    "## Exercise 1.2:\n",
    "\n",
    "1. Read the images you got from exercise 1 (linear stretching) and exercise 2 (denoised) from the previous session.  If you were not able to obtain them you can find these under the folder \"Previous_session\": 'stretched.mha' and 'median_filtered.mha'.\n",
    "\n",
    "2. Apply the Otsu multi-thresholding algorithm to the new images. Visualize the results using ```show_segments```.\n",
    "\n",
    "3. In each case select the segment where the tumor is distinguishable and extract it using the function of point 3 of the previous exercise. It is possible that in the selected segment the tumor is connected to other structures. \n",
    "\n",
    "4. Use the following 3 images: \n",
    "    - (1) the tumor mask without post-processing of exercise 1.1, \n",
    "    - (2) tumor mask obtained from the linear stretched image \n",
    "    - (3) tumor mask obtained from the denoised image. \n",
    "   \n",
    "   Via a \"majority voting\" approach combine the images to obtain a better segmentation : \n",
    "    - Start by creating an empty 2D array with equal dimensions to one of the previous images (if needed change from ITK image to np.array using: ```sitk.GetArrayFromImage()``` and vice-versa).\n",
    "    - Iterate over each pixel position of the 3 images, average the pixel values and if this is greater than 0.5, place a 1 in the same position in the 2D array.\n",
    "    \n",
    "5. Apply ```sitk.BinaryFillholeImageFilter``` (```SetForegroundValue``` to 1) and ```sitk.BinaryDilateImageFilter``` (```SetForegroundValue``` to 1, ```SetKernelRadius ``` to 2 and ```SetKernelType``` to ```sitk.sitkBall()```.\n",
    "\n",
    "6. Calculate the metrics (DICE coefficient, Jaccard coefficient, false positive error, false negative error and Hausdorff distance) between the ground truth and the images from point 4 and 5.\n",
    "\n",
    "## Report\n",
    "<font color=blue> \n",
    "- Plot a one-by-five image comparison of the ground truth and the four tumor segmentations: (1) Exercise 1.1 no post-processing, (2) Exercise 1.1 post-processing, (3) Exercise 1.2 majority voting no post-processing and (4) Exercise 1.2 majority voting post-processing.\n",
    "- Plot the results of each of the evaluation metric for different methods using a ```matplotlib``` barplot.\n",
    "- Discuss your results. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Your answer here </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to show a new image which is in sitk format\n",
    "def show_image(image):\n",
    "    '''\n",
    "    This function converts a sitk image to an array and shows it\n",
    "    Inputs:\n",
    "        - image: Image in SimpleITK format that will be plot\n",
    "    Outputs:\n",
    "        - A new plot\n",
    "    '''\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    plt.imshow(array, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Function to show the results of the multi-otsu threshold\n",
    "def show_segments(original_image, segments, thresholds):\n",
    "    '''\n",
    "    Plot the results of the multi-threshold filter. Additionally, it shows the histogram of the image and \n",
    "    the correspondant thresholds. Additionally, it displays the resultant segments of the algorithm.\n",
    "    Inputs:\n",
    "        - original_image: The original image in sitk format.\n",
    "        - segments: Segmented image obtained from the multi-threshold filter. Format: sitk.\n",
    "        - thresholds: Numeric cut-off thresholds. Format: float.\n",
    "    Outputs:\n",
    "        - A plot of the original image, the resultant segments, its histogram with thresholds and each of\n",
    "        the segments.\n",
    "    '''\n",
    "    # Pass images to arrays\n",
    "    original_array = sitk.GetArrayFromImage(original_image)\n",
    "    segments_array = sitk.GetArrayFromImage(segments)\n",
    "    \n",
    "    # Use the threshold values to generate the regions\n",
    "    regions = np.digitize(original_array, bins=thresholds)\n",
    "    \n",
    "    # Plot\n",
    "    fig3 = plt.figure(constrained_layout=True, figsize=(10,10))\n",
    "    gs = fig3.add_gridspec(4, 4)\n",
    "    \n",
    "    # Original image \n",
    "    f3_ax1 = fig3.add_subplot(gs[0:-2, 0:-2])\n",
    "    f3_ax1.imshow(original_array, cmap='gray')\n",
    "    f3_ax1.set_title('Original image')\n",
    "    \n",
    "    # Regions\n",
    "    f3_ax2 = fig3.add_subplot(gs[0:-2, 2:])\n",
    "    f3_ax2.imshow(regions, cmap='seismic')\n",
    "    f3_ax2.set_title('Result from Otsu multithresholding ')\n",
    "    \n",
    "    # Histogram\n",
    "    f3_ax3 = fig3.add_subplot(gs[2:, 0:-2])\n",
    "    f3_ax3.hist(original_array.ravel(), bins=64, histtype = 'bar')\n",
    "    f3_ax3.set_title('Histogram')\n",
    "    for thrs in thresholds:\n",
    "        f3_ax3.axvline(thrs, color='r')\n",
    "    \n",
    "    # Segments\n",
    "    f3_ax4 = fig3.add_subplot(gs[2, 2])\n",
    "    f3_ax4.imshow(segments_array == 1, cmap='gray')\n",
    "    f3_ax4.set_title('1st segment')\n",
    "    f3_ax5 = fig3.add_subplot(gs[2, 3])\n",
    "    f3_ax5.imshow(segments_array == 2, cmap='gray')\n",
    "    f3_ax5.set_title('2nd segment')\n",
    "    f3_ax6 = fig3.add_subplot(gs[3, 2])\n",
    "    f3_ax6.imshow(segments_array == 3, cmap='gray')\n",
    "    f3_ax6.set_title('3rd segment')\n",
    "    f3_ax7 = fig3.add_subplot(gs[3, 3])\n",
    "    f3_ax7.imshow(segments_array == 4, cmap='gray')\n",
    "    f3_ax7.set_title('4th segment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> SOLUTION </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Region growing\n",
    "\n",
    "Region growing algorithms start by defining an initial region, known as seed point, usually set by a user inside the object to be segmented. Afterwards, an iterative search is performed. In each iteration all neighboring pixels of the seed are evaluated and a criterion is used to determine if they should also be considered part of the object. If so, they are added to the region and their neighbors will now also be evaluated in the following iteration.\n",
    "\n",
    "The criterion to add neighbours varies between applications, these could be brightness, color, texture, gradient, or geometric properties. The most common approach is to take into account the intensity of the neighoring pixels. If their intensity is between a lower and upper threshold values, they are included within the region. The algorithm has the benefit of taking into account spatial connectivity, thereby enabling to limit the segmentation to connected regions.\n",
    "\n",
    "<img src=\"./images/region_growing.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "**(i)** Angio-MRI with seed point at the aortic arch **(ii) - (v)** Region growing from the seed point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From previous exercise you noticed that it was not possible to directly separate the tumor from other structures, hence the need to isolate it using sitk.ConnectedComponentImageFilter(). Additionally, extra information from other modalities was required. In this exercise you will attempt to isolate the tumor by implementing a region growing algorithm in its simplest form.\n",
    "\n",
    "The algorithm should output a binary image with pixel values equal to 1 for the structure under study and 0 for all other pixels. As inputs it should use a seed point and two threshold values (lower and uppper). \n",
    "\n",
    "1. Start by reading the image 'BraTS2021_01666_flair.mha' and the ground-truth segmentation 'BraTS2021_01666_seg.mha' from the folder 'BraTS2021_01666', read the ground truth as 'sitk.sitkUInt8'.\n",
    "2. Use the function ```set_seed_point()``` to visualize the image and select a seed point. Select a point in the center of the tumor.\n",
    "3. Previous function returns the coordinates of the seed point. Get the pixel intensity at the seed point. \n",
    "4. Build a function that implements a region growing algorithm. It has to compare the intensity of the seed point with the neighboring intesities. If they are within the limits, these pixels are added to the region. Evaluate the performance of the algorithm if the following threshold values are taken into account:\n",
    "\n",
    "    - Seed point intensity $\\pm$10, $\\pm$20 and $\\pm$30. \n",
    "\n",
    "5. Assess its performance by considering 4 and 8 nearest neighbors. \n",
    "\n",
    "    **To build this function:**\n",
    "    - Start from the seed point\n",
    "    - List the 4 (or 8) neighboring pixels\n",
    "    - Check if their intensity falls within the threshold boundaries. \n",
    "    - Grow your region by adding the pixels that meet the condition.\n",
    "    - List all new neighboring pixels of the obtained new region.\n",
    "    - Repeat until there are no more pixels added.\n",
    "    \n",
    "**Hint:** It may be handy to store the indexes (locations) and values of pixels which are already marked inside and those, which are currently marked as neighbors. For example: 0 - outside, 1 - inside, 2 - neighbor.\n",
    "\n",
    "5. Apply ```sitk.BinaryFillholeImageFilter``` (```SetForegroundValue``` to 1) as post-processing to the resultant segmentations using the threshold of $\\pm$30. \n",
    "6. Calculate the metrics (DICE coefficient, Jaccard coefficient, false positive error, false negative error and Hausdorff distance) between the ground truth and the obtained segmentations (8 in total: 3 thresholds x 2 neighbouring strategies, and 2 post-processed images).\n",
    "\n",
    "**Reminder:** Be sure to have ```matplotlib == 3.1.3``` and ```Tkinter == 8.6```.\n",
    "\n",
    "## Report\n",
    "<font color=blue> \n",
    "- Plot a two-by-five image comparison of the ground truth and the tumor segmentations at each threshold level for each number of neighbors.\n",
    "- Plot a relation (```plt.plot()```) between the number of thresholds used (x-axis) against the evaluated metric. On each figure include two plots, one for 4 neighbours and the other for 8 neighbours.\n",
    "- Discuss your results.\n",
    "- In the clinical practice, you are often faced with a trade-off between the false positive and false negative error of your segmentation (one is low, the other is high). In the case of brain tumour segmentation, would you prefer to obtain:\n",
    "    - oversegmenated volume\n",
    "    - undersegmented volume\n",
    "    - Why? Which case corresponds to what values of false positive and false negative errors?\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Your answer here </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Function to show a new image which is in sitk format\n",
    "def show_image(image):\n",
    "    '''\n",
    "    This function conver a sitk image, converts it to array and shows it\n",
    "    Inputs:\n",
    "        - image: Image in SimpleITK format that will be plot\n",
    "    Outputs:\n",
    "        - A new plot\n",
    "    '''\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    \n",
    "    plt.imshow(array, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Function to select a seed point from the image\n",
    "def set_seed_point(image):\n",
    "    '''\n",
    "    This function opens a new window and displays the image, select a point inside the tumor to set the seed point.\n",
    "    Inputs:\n",
    "        - image: Image where the seed point will be set. Format sitk.\n",
    "    Outputs:\n",
    "        - seed: 'x' and 'y' coordinates of the seed point\n",
    "    '''\n",
    "    matplotlib.use('TkAgg')\n",
    "    \n",
    "    # Pass image to array\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    \n",
    "    # Select seed point\n",
    "    plt.figure()\n",
    "    plt.imshow(array, cmap = 'gray')\n",
    "    plt.show(block=False)\n",
    "    #User selects the intial seed point\n",
    "    print ('\\nPlease select the initial seed point')\n",
    "\n",
    "    pseed = plt.ginput(1)\n",
    "    x = int(pseed[0][0])\n",
    "    y = int(pseed[0][1])\n",
    "    seed = x, y\n",
    "\n",
    "    print ('you clicked:',seed)\n",
    "\n",
    "    # Close figure\n",
    "    plt.close('all')\n",
    "    \n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> SOLUTION </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
