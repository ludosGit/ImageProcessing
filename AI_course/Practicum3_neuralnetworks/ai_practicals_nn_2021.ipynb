{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "toc",
    "id": "6QTctwZ0MDve"
   },
   "source": [
    ">[Practical session Artificial Intelligence: Neural Networks](#scrollTo=PP0TTjo2IHcx)\n",
    "\n",
    ">>[global settings](#scrollTo=wVUwqOFb2vPA)\n",
    "\n",
    ">>[Usefull packages](#scrollTo=NelzDOpCgtJi)\n",
    "\n",
    ">>>[Tensorflow and Keras](#scrollTo=KSrwJX4S0Ii3)\n",
    "\n",
    ">>[Downloading database](#scrollTo=swisGM3dhew1)\n",
    "\n",
    ">[Database](#scrollTo=jjgUQifPbfzP)\n",
    "\n",
    ">[Training](#scrollTo=Qyh-k6lhow8d)\n",
    "\n",
    ">>[Building a neural network](#scrollTo=_FLKD5pdofZ6)\n",
    "\n",
    ">>[Apples or not apples](#scrollTo=k-zqmB3EpFj4)\n",
    "\n",
    ">>>[Saving and downloading model.](#scrollTo=flNrtOxp1VJF)\n",
    "\n",
    ">>>[Learning rate](#scrollTo=eE2IqCqz3lGL)\n",
    "\n",
    ">>>[Batch size](#scrollTo=3LCm9Rl-1ODW)\n",
    "\n",
    ">>[Fruit classifcation](#scrollTo=E8pTIAmKL29f)\n",
    "\n",
    ">[Testing on own data](#scrollTo=KWq2N5EoRuTu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PP0TTjo2IHcx"
   },
   "source": [
    "#Practical session Artificial Intelligence: Neural Networks\n",
    "\n",
    "Assistants: Shaoguang Huang, Srdan Lazendic, Nicolas Vercheval, Nina Žižakić\n",
    "\n",
    "Professor: Aleksandra Pižurica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVUwqOFb2vPA"
   },
   "source": [
    "## global settings\n",
    "\n",
    "For faster processing, make sure to set in *Runtime > Change runtime type*, *hardware accelerator* to *GPU*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NelzDOpCgtJi"
   },
   "source": [
    "##Usefull packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSrwJX4S0Ii3"
   },
   "source": [
    "### Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgRGzNEHh0Ee"
   },
   "outputs": [],
   "source": [
    "# Install TensorFlow\n",
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "#tf.compat.v1.disable_v2_behavior()\n",
    "%load_ext tensorboard\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0yduGuahNkh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "print('Tensorflow version:')\n",
    "!python3 -c 'import tensorflow as tf; print(tf.__version__)'  # for Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "il77nNxjgsTk"
   },
   "outputs": [],
   "source": [
    "import datetime, os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, InputLayer\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "precision, recall = Precision(), Recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swisGM3dhew1"
   },
   "source": [
    "## Downloading database\n",
    "\n",
    "Follow the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6AweEjqfh0hL"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth, files\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HvoHODGLhcIx"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "googledrive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r35XxJhJArtV"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1R7uTeV5Bk4C"
   },
   "outputs": [],
   "source": [
    "id = '17T6-1E6Nk37O6S6sUhprQvTfLYmXQb-b'\n",
    "download = googledrive.CreateFile({'id': id})\n",
    "download.GetContentFile('2021_fruits_dataset.zip')\n",
    "!unzip '2021_fruits_dataset.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjgUQifPbfzP"
   },
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WUdYV2db0lW-"
   },
   "outputs": [],
   "source": [
    "class_names = ['apple', 'banana', 'cherry', 'grape', 'onion', 'peach', 'pear', 'pepper', 'plum', 'potato', 'tomato']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AShkD0cdb4Ee"
   },
   "outputs": [],
   "source": [
    "# rescale images to range [0; 1]\n",
    "def im_preprocess(im):\n",
    "\n",
    "    if im.max() > 1.:\n",
    "        # to float instead of uint8\n",
    "        im = np.divide(im, 255., dtype=np.float16)\n",
    "\n",
    "    assert im.max() <= 1.\n",
    "\n",
    "    return im\n",
    "\n",
    " \n",
    "def get_data(dataset, factor_downsample = 1):\n",
    "    \"\"\"\n",
    "    :param factor_downsample: skips images to reduce dataset size\n",
    "    \"\"\"\n",
    "\n",
    "    assert dataset in ['training', 'validation', 'testing']\n",
    "\n",
    "    print(f'Loading {dataset}-dataset')\n",
    "\n",
    "    if dataset == 'training':\n",
    "        home_folder = '2021_fruits_dataset/1training'\n",
    "    elif dataset == 'validation':\n",
    "        home_folder = '2021_fruits_dataset/2validation'\n",
    "    else:\n",
    "        home_folder = '2021_fruits_dataset/3test'\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    folder_list = sorted(os.listdir(home_folder))\n",
    "\n",
    "    for folder in folder_list:\n",
    "        folder_lower = folder.lower()\n",
    "\n",
    "        if 'apple' == folder_lower[:5]:            \n",
    "            y_index = class_names.index('apple')\n",
    "        \n",
    "        elif 'banana' in folder_lower:\n",
    "            y_index = class_names.index('banana')\n",
    "            \n",
    "        elif 'cherry' in folder_lower[:6]:\n",
    "            y_index = class_names.index('cherry')\n",
    "            \n",
    "        elif 'grape ' in folder_lower:\n",
    "            y_index = class_names.index('grape')\n",
    "            \n",
    "        elif 'onion' in folder_lower:\n",
    "            y_index = class_names.index('onion')\n",
    "            \n",
    "        elif 'peach' in folder_lower:\n",
    "            y_index = class_names.index('peach')\n",
    "            \n",
    "        elif 'pear' in folder_lower:\n",
    "            y_index = class_names.index('pear')\n",
    "\n",
    "        elif 'pepper' in folder_lower:\n",
    "            y_index = class_names.index('pepper')\n",
    "            \n",
    "        elif 'plum' in folder_lower:\n",
    "            y_index = class_names.index('plum')\n",
    "            \n",
    "        elif 'potato' in folder_lower:\n",
    "            y_index = class_names.index('potato')\n",
    "            \n",
    "        elif 'tomato' in folder_lower:\n",
    "            y_index = class_names.index('tomato')\n",
    "        else:\n",
    "            # Not included in assignment\n",
    "            raise ValueError(f'Unknown class in {folder_lower}')\n",
    "            continue\n",
    "\n",
    "        folder_path = os.path.join(home_folder, folder)\n",
    "        file_list = sorted(os.listdir(folder_path))\n",
    "        for im_file in file_list:\n",
    "            \n",
    "            name, _ = os.path.splitext(im_file)\n",
    "            index_file = int(name.split('_')[-2])   # Second to last! Last element is width image (=100)\n",
    "            if (index_file % factor_downsample) != 0:\n",
    "                continue\n",
    "        \n",
    "            im_path = os.path.join(folder_path, im_file)\n",
    "\n",
    "            im = plt.imread(im_path)\n",
    "            im = im_preprocess(im)\n",
    "\n",
    "            x.append(im)\n",
    "            y.append(y_index)\n",
    "\n",
    "    print(f'Finished {dataset}-dataset')\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDH1Qc-abg99"
   },
   "outputs": [],
   "source": [
    "print(class_names)\n",
    "\n",
    "print('Training data')\n",
    "x_train, y_train = get_data('training', factor_downsample = 1)\n",
    "x_valid, y_valid = get_data('validation', factor_downsample = 1)\n",
    "x_test, y_test = get_data('testing', factor_downsample = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qyh-k6lhow8d"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GLJxgiNZmqTe"
   },
   "outputs": [],
   "source": [
    "x_train = np.stack(x_train, axis=0).astype(np.float16)\n",
    "x_valid = np.stack(x_valid, axis=0).astype(np.float16)\n",
    "x_test = np.stack(x_test, axis=0).astype(np.float16)\n",
    "\n",
    "y_train = np.stack(y_train, axis=0).astype(np.int16)\n",
    "y_valid = np.stack(y_valid, axis=0).astype(np.int16)\n",
    "y_test = np.stack(y_test, axis=0).astype(np.int16)\n",
    "\n",
    "def y_to_apple(y):\n",
    "    i_apple = class_names.index('apple')\n",
    "    y_apple = np.equal(y, i_apple, dtype=np.int16)\n",
    "    return y_apple\n",
    "\n",
    "y_train_apple = y_to_apple(y_train)\n",
    "y_valid_apple = y_to_apple(y_valid)\n",
    "y_test_apple = y_to_apple(y_test)\n",
    "\n",
    "y_train_fruit = to_categorical(y_train, num_classes=None)\n",
    "y_valid_fruit = to_categorical(y_valid, num_classes=None)\n",
    "y_test_fruit = to_categorical(y_test, num_classes=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FLKD5pdofZ6"
   },
   "source": [
    "## Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hiYy_2hNBRz5"
   },
   "outputs": [],
   "source": [
    "pract_folder = 'drive/My Drive/AI_pract3_nn2021'\n",
    "logs_folder = os.path.join(pract_folder, 'logs')\n",
    "weights_folder = os.path.join(pract_folder, 'weights')\n",
    "if not os.path.exists(weights_folder):\n",
    "    os.makedirs(weights_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WYA0EJ-zolNu"
   },
   "outputs": [],
   "source": [
    "def get_model_base_simple(k = 4):  \n",
    "    model = Sequential()\n",
    "    model.epoch = 0     # to save amount of epochs trained\n",
    "\n",
    "    model.add(InputLayer((100, 100, 3)))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2))) # downsampling\n",
    "    model.add(Conv2D(k, (3, 3), activation='elu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(k, (3, 3), activation='elu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(k, (4, 4), activation='elu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(k, activation='elu'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_apple_simple(lr, loss='mse'):\n",
    "  \n",
    "    model = get_model_base_simple()\n",
    "\n",
    "    # single class classification\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                optimizer=SGD(lr),\n",
    "                metrics=['accuracy', precision, recall])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_fruit_simple(lr):\n",
    "    model = get_model_base_simple()\n",
    "  \n",
    "    ### To implement yourself\n",
    "    model.add(None)\n",
    "    model.compile(loss=None,\n",
    "                optimizer=SGD(lr),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MeINypx5yIhE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-zqmB3EpFj4"
   },
   "source": [
    "## Apples or not apples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPr0feKUpg6f"
   },
   "outputs": [],
   "source": [
    "model_apple = get_model_apple_simple(lr=1e-2)\n",
    "\n",
    "### uncomment if you already have a trained network\n",
    "# model_apple = keras.models.load_model(os.path.join(weights_folder, '<apple.hdf5>'))\n",
    "\n",
    "model_apple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wfYOiZufD-eh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xz-AqW-yo5Oi"
   },
   "source": [
    "This will give you live feedback of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gXMEjz_Gv-64"
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78-2ODpup5_Q"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir 'drive/My Drive/AI_pract3_nn2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLUQGFTOoOK7"
   },
   "outputs": [],
   "source": [
    "def train_model(epochs = 20):\n",
    "\n",
    "    t_now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    logdir = os.path.join(logs_folder, t_now)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, write_graph=False)\n",
    "\n",
    "    weightdir = os.path.join(weights_folder, f\"{t_now}_\" + \"{epoch}.hdf5\")\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(weightdir)\n",
    "\n",
    "    model_apple.fit(x_train, y_train_apple, validation_data=(x_valid, y_valid_apple),\n",
    "                    initial_epoch = model_apple.epoch,\n",
    "                    batch_size=64, epochs=model_apple.epoch + epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=[tensorboard_callback, checkpoint]\n",
    "                    )\n",
    "    model_apple.epoch += epochs\n",
    "\n",
    "train_model()\n",
    "print(model_apple.epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iCiqEvcTwu0o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UM8knTrDwjrZ"
   },
   "outputs": [],
   "source": [
    "y_test_pred = model_apple.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2rg5vyokoylE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flNrtOxp1VJF"
   },
   "source": [
    "###Saving and downloading model.\n",
    "\n",
    "Alternatively you can download it manually through: *View -> Table of contents -> Files -> Right click* **.h5-> Download*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "932mtVjs1KOg"
   },
   "outputs": [],
   "source": [
    "path = os.path.join(weights_folder, 'apple.h5')\n",
    "model_apple.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eE2IqCqz3lGL"
   },
   "source": [
    "### Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ng696_MOHEX1"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "lst_train_cost = []\n",
    "lst_valid_cost = []\n",
    "lst_lr = [1E-4,1E-3,1E-2,1E-1,1,10,100,1000]\n",
    "model_apple1 = get_model_apple_simple(lr=0)\n",
    "for lr_rate in lst_lr:\n",
    "    model_apple = get_model_apple_simple(lr=0)\n",
    "    model_apple.compile(loss='mse',\n",
    "                optimizer=SGD(lr_rate), # setting the learning rate\n",
    "                metrics=['accuracy'])\n",
    "    hist = model_apple.fit(x_train, y_train_apple, validation_data=(x_valid, y_valid_apple),\n",
    "              batch_size=32, \n",
    "              initial_epoch = 1,\n",
    "              epochs=20,\n",
    "              verbose=1)\n",
    "    lst_train_cost.append(hist.history['loss'][-1])\n",
    "    lst_valid_cost.append(hist.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJgKtA7i4ZhJ"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lst_lr, lst_train_cost, label='training data')\n",
    "plt.plot(lst_lr, lst_valid_cost, label='validation data')\n",
    "\n",
    "plt.xlabel('learning rate')\n",
    "plt.ylabel('loss')\n",
    "plt.xscale('log')\n",
    "plt.title('Loss in while increasing the learning rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUYITQRC66Mr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LCm9Rl-1ODW"
   },
   "source": [
    "### Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d871oKvHTfAU"
   },
   "outputs": [],
   "source": [
    "model_apple = get_model_apple_simple(lr=1e-2)\n",
    "def train_model_batch(epochs, batch_sz):\n",
    "\n",
    "    t_now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    logdir = os.path.join(logs_folder, t_now)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, write_graph=False)\n",
    "\n",
    "    weightdir = os.path.join(weights_folder, f\"{t_now}_\" + \"{epoch}.hdf5\")\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(weightdir)\n",
    "\n",
    "    model_apple.fit(x_train, y_train_apple, validation_data=(x_valid, y_valid_apple),\n",
    "                    initial_epoch = model_apple.epoch,\n",
    "                    batch_size=batch_sz, epochs=model_apple.epoch + epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=[tensorboard_callback, checkpoint]\n",
    "                    )\n",
    "    model_apple.epoch += epochs\n",
    "\n",
    "train_model_batch(epochs = 20, batch_sz = 64)\n",
    "print(model_apple.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HD7ll4XPjjGT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8pTIAmKL29f"
   },
   "source": [
    "## Fruit classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfACQCMtL45T"
   },
   "outputs": [],
   "source": [
    "# to implement\n",
    "def get_model_fruit_simple():\n",
    "  return None\n",
    "\n",
    "model_fruit = get_model_fruit_simple()\n",
    "\n",
    "model_fruit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-B_HtqZNtPh"
   },
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWq2N5EoRuTu"
   },
   "source": [
    "# Testing on own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCTJNVtnlh3f"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PFMFLv0QtfN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Bwd2dAVQ4Ne"
   },
   "outputs": [],
   "source": [
    "url = 'https://images-na.ssl-images-amazon.com/images/I/319J7YpfyNL.jpg'\n",
    "\n",
    "def open_image(path):\n",
    "\n",
    "    response = requests.get(path)\n",
    "    img = np.array(Image.open(BytesIO(response.content)))\n",
    "\n",
    "    resize = cv2.resize(img, (100, 100))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(resize)\n",
    "    plt.plot()\n",
    "\n",
    "    single_x = np.stack([resize], axis=0)\n",
    "    im_resize = im_preprocess(single_x)\n",
    "\n",
    "    # TODO preprocessing \n",
    "    ...\n",
    "\n",
    "    return im_resize\n",
    "\n",
    "single_x = open_image(url) # '<your_fruit.jpg>'\n",
    "\n",
    "model_apple = load_model(weights_folder + '/<model_apple>.hdf5')\n",
    "model_fruit = load_model(weights_folder + '/<model_fruit>.hdf5')\n",
    "\n",
    "pred_apple = model_apple.predict(single_x)\n",
    "pred_fruit = model_fruit.predict(single_x)\n",
    "\n",
    "print(pred_apple)\n",
    "print(pred_fruit)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ai_practicals_nn_2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
